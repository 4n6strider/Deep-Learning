{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST/data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf #imports tensorflow as tf. Tensorflow is an n-dimensional matrix, just like a 1-D vector, 2-D array, 3-D array etc.\n",
    "import numpy as np #imports numpy as np. Numpy is used for basic matrix multiplication, addition.\n",
    "from tensorflow.examples.tutorials.mnist import input_data #imports mnist input data from tensorflow examples. \n",
    "#Mnist data set consists of images of numbers from 0-9, each image is a 28*28 dimensional. There are total 60k training images and 10k test images.\n",
    "mnist = input_data.read_data_sets(\"MNIST/data\", one_hot = True) #using input data call read data sets from a folder MNIST/data and store in mnist.\n",
    "#one hot vector is used which means at once only one class will be true. Since our images have labels 0-9 that means out of all 10 classes only 1 class will be true at a time rest all will be zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAAEMCAYAAAAiW8hnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAFgdJREFUeJzt3Xu4XfOdx/H3x/2SyA2RuCRVQmNoaKo6Y8jUpaIUYx4t\nHk3RJ26Z6oWHyTMdKTW0o62Ztkg6qLpN05JKVJVSxcxoiyFEGpREE7mJpIiKhu/8sdb52Y5zfvvs\ns/c5e5/k83qe82Sf9V2X7157n8/+rbVX9lZEYGYGsEGzGzCz1uFAMLPEgWBmiQPBzBIHgpklDgQz\nSxwI3SRpiqQbenmbP5c0odHz1tjD30qa1+j19gRJp0m6vLw9UlJI2qgLy42TtLCb2+z2sh2say9J\n/9OIdXVVnwqE8kG9Q9JKSUskfbftAZY0StJtkpZLelnSLyTtVrHsZyW9Jem1ip9xFfUxkh6Q9CdJ\nCyV9paJW94NcPhl3qWcdETE+Iq5r9Lw19vBAROxWfc7mkrQJ8M/AvzW7l5zc8y4iZgOrJB3ZW/30\nqUAArgCWAcOAMcCBwJllbSAwE9gNGAr8Frit3fL/GxH9Kn7uq6jdBNwPDG5br6RP9tQdaa8rr1xW\nk6OA30fEomY3UkW1592NwGm91UxfC4T3AdMj4o2IWALcCewBEBG/jYirI+LliPgL8G1gN0lDurju\nkcCNEfFWRPwBeBDYQ9KWwM+B4RUji+HlMptI+qGkVyXNkTS2oxVLur+8+Xi5/KfaRh2SzpO0BLhW\n0iBJt5ejnJXl7R0q1nOfpM+Vtz8r6UFJl5XzPi9pfDfnfZ+k+8v78UtJ3+vscKj9aEnSfEnnSpot\nabWkqyUNLQ9Z2tY3qGL+H5ejuz+V29yjojZE0ixJr0j6naSvSXqwor67pLvLEeA8ScdlHs/xwK87\nK0o6WdLcssfnJL3nj07SZEkvlffxxIrpm5b78gVJSyVdJWnzTC85I+ngeVdRvw84SNKm3Vx/Tfpa\nIFwOfFrSFpK2p3jQ7+xk3gOAJRGxomLa3uUD/LSkr7R7Vb4c+IykjctDjY8Cv4yI1eV2XqwYWbxY\nLvNJ4L94Z3Ty3Y4aiYgDypsfLJf/Ufn7dhSvDCOAiRSPx7Xl7zsBf+5snaWPAPOArYFvAFdLUjfm\nvYliRDUEmAKclNlmR44FDgFGAUdSBOhkYJvyPn2+Yt6fA7sC2wKPUrwCtvkesJpiv0wofwAog/nu\nstdtgU8DV0ga3UlPe5b3tzPLgCOArYCTgW9L2qeivh3Fvtq+7GOa3jkEvbS8r2OAXcp5/qWjjUi6\nQtIVmT46fN61FcsRzl8oRr49LyL6zA/wAeARYC0QwA8AdTDfDsAi4PiKaTtTjDA2oHiyPAX8U0X9\nr4FnK9b91YraOGBhu21MoQiMtt9HA3/O9B7ALu3W+SawWWaZMcDKit/vAz5X3v4s8GxFbYtyG9vV\nMi9F8KwFtqio3wDc0ElP79oXwHzgxIrfbwGurPj9H4GfdrKugWUfA4ANKZ/4FfWvAQ+Wtz8FPNBu\n+anABZ2s+xngsIrfR5bb2qiT+X8KnF1xH9cCW1bUpwNfAUQRWu+vqH0UeL6z50qV53Snz7uKeRYB\nB/TG31ifGSFI2oBiNHArsCVFeg8Cvt5uvm2Au4ArIuLmtukR8VxEPB8Rb0fEE8CFwD+Uywwu130h\nsBmwI/BxSWeSt6Ti9uvAZjWeC1geEW9U9L6FpKmSFkh6heLYcqCkDattPyJeL2/2q3He4cDLFdMA\n/ljDfQBYWnH7zx383g9A0oaSLpX0h/L+zS/n2ZpiNLFRu21X3h4BfETSqrYf4ESKUOvISqB/Zw1L\nGi/pofLwYxVweNlHWj6K0WGbBRT7ahuKQH2koo87y+k1qeF51x9YVev6u6PPBALF0Hon4LsRsSaK\nQ4FrKR5IAMpj1buAmRFxcZX1BUXaQzF6eCsifhgRayNiIcWhwOEV8/aE9uv9MsXQ8CMRsRXFYQ8V\nffaExcBgSVtUTNuxh7Z1AsXJvoMpRgUjy+kCllO8Su5QMX9lH38Efh0RAyt++kXEGZ1sazbFsP49\nyuPxW4DLgKERMRC4g3fv50HlYUqbnYAXgZcoQm6Pij4GRERnQZxT7XlHeWi8CfnDn4bpM4EQES8B\nzwNnSNpI0kCKY7vZAJK2An4B/HdEnN9++fIVYWh5e3eK4V/buxBPF5N1gqQNJG1HMUSdXdaXAkMk\nDajjLiyleALk9Kd4sq0qXz0uqGN7XRIRC4CHgSmSNpH0UYrzAD2hP7AGWEHxKvuvFX28RTH6m1KO\nlHYHPlOx7O3AKEknlcfbG0v6sKQPdLKtOyjO2ndkE2BTyhAqT7Ae2sF8Xy33yd9SnG/4cUS8DXyf\n4pzDtlD80Ur6eJf2wLtVe95R3od7I2JNN9Zfsz4TCKW/Bw6jeCCfpTjm/GJZOwb4MHCy3n2twU5l\n/SBgtqTVFE+WWymfkBHxSrnuL1IMNR8DnqQ4hiUifg/cDDxXDhPb3mWoxRTgunL5zs6OXw5sTvEq\n9BCdnzBttBMpjoNXUNznH1H84TbaDymG3osozuE81K4+iWLksAS4nmKfrwGIiFcp/mg/TfFKvYTi\ncLGzs++zgN07eqzKdX2e4rzASoqRy8x2sy0pay9SnPg8vXweAJxH8fx7qDz0+SWdnPQr34G4qqNa\ntedd6USgw+V7RG+cqOjgJMlhFEOgZ4Hzm9FDlf7mA0+UD9DDLdDPNRRnxZ+smDaY4qz7M+W/gxq4\nvR/RwcmtGvubQvGH/1j5c3g3+vg6cF0d92MiRcjuCPyKIoTm8M7Jwx7bhzX22Vl/V1IEYrf3Yc29\nNOHObwj8gWL4vAnwODC6GQ9Epsf5wNbN7qOinwOAfdr9wX2jLUyB84Gv17H+DwPvpxgxHga8Aexd\nZ39TgHNq7GN3YC+KY/l9KUZKRzdg/w0D9ilv96cYqo9u5D7sof5q3of1/jTjkGFfirfAnouINylO\nohzVhD76jIi4H3i53eSjgLZLk68Djq5jE9tRvE35GvAfwBkR8X919tcd/SkO5VZTjFK+yXuvNq1Z\nRCyOiEfL268CcymuHWjkPuyJ/npdMwJhe979dtJCmnTnMwK4S9IjkiY2u5lODI2IxeXtJRSXa3dL\nRMyKiB0jYouIGBUR1zamRSapuILxGlVcrZjp43cRsUvZx/si4pIoXzYbRdJIYG/gNzRwHzZKu/6g\nxn1Yr752UrG37B8R+1BcoXiWpAOqLdBM5R9Nq31a7pUUhyFjKN7a/GZz2wFJ/SjebvxCFCf0klbY\nhx301+v7sBmBsIh3v7/cdlVhy4jyP8RExDJgBsVhTqtZKmkYQPnvsib38y4RsTSK6/Pb3qZr6j6U\ntDHFH9uNEXFrObll9mFH/TVjHzYjEH4H7KriP9RsQvE2Uvu3fJpG0paS+rfdpnir68nmdtWhmbxz\nrf8EGnCs3Uhtf2ilY2jiPiz/z8bVwNyI+FZFqSX2YWf9NWMfqsGHaF3bqHQ4xdtBGwLXRPWrCnuN\npJ0pRgVQXEp7U7P7k3QzxTXyW1Nc4HQBxbX30ymuoFsAHBcRjTix16j+xlEMdYPiXZvTKo7Xe7u/\n/YEHKN5KfrucPJniOL3p+zDT3/H08j5sSiCYWWvySUUzSxwIZpY4EMwscSCYWeJAMLOkqYHQwpcF\nA+6vXq3cXyv3Bs3rr9kjhJZ+UHB/9Wrl/lq5N2hSf80OBDNrIXVdmCTpMODfKa44/M+IuLTK/L4K\nyqxJIqLqZ3N2OxDKTwJ+muLz+BdS/B+F4yPiqcwyDgSzJulKINRzyOAPOjFbx9QTCH3hg07MrAY9\n/gWj5dsnrX5G18yoLxC69EEnETENmAY+h2DW6uo5ZGjpDzoxs9p1e4QQEWslTaL4tqS2DzqZ07DO\nzKzX9eoHpPiQwax5evptRzNbxzgQzCxxIJhZ4kAws8SBYGaJA8HMEgeCmSUOBDNLHAhmljgQzCxx\nIJhZ4kAws8SBYGaJA8HMEgeCmSUOBDNLHAhmljgQzCxxIJhZ4kAws8SBYGaJA8HMEgeCmSUOBDNL\nHAhmljgQzCxxIJhZ4kAws8SBYGaJA8HMko2a3YB1Xb9+/bL1yZMnZ+tHHHFEtr7HHnvU3FOlDTbI\nv77cdttt2fp5552Xrc+bN6/mnqw2dQWCpPnAq8BbwNqIGNuIpsysORoxQvi7iHipAesxsybzOQQz\nS+oNhADukvSIpImNaMjMmqfeQ4b9I2KRpG2BuyX9PiLur5yhDAqHhVkfUNcIISIWlf8uA2YA+3Yw\nz7SIGOsTjmatr9uBIGlLSf3bbgOHAk82qjEz632KiO4tKO1MMSqA4tDjpoi4uMoy3dvYemLAgAHZ\n+g033JCtjx8/vpHt1ExStl7tufbCCy9k64ceemi2/uyzz2br67uIyD9A1HEOISKeAz7Y3eXNrPX4\nbUczSxwIZpY4EMwscSCYWeJAMLPEgWBmSbevQ+jWxnwdQtapp56arU+dOrWXOumeeq9DqGbu3LnZ\n+p577lnX+td1XbkOwSMEM0scCGaWOBDMLHEgmFniQDCzxIFgZokDwcwSfy9DC/nYxz5W1/LV3udf\nuXJltj548OC6tr9s2bJs/YorrsjWjzvuuGx9yJAhNfdktfEIwcwSB4KZJQ4EM0scCGaWOBDMLHEg\nmFniQDCzxNchrEMmTsx/Y96MGTOy9TPOOCNbX7FiRbY+bdq0bP2cc87J1ocPH56tr1mzJlu3+nmE\nYGaJA8HMEgeCmSUOBDNLHAhmljgQzCxxIJhZ4usQetF+++2XrR9yyCF1rf/222/P1letWpWtX3LJ\nJXVtv5p+/fpl6wMGDMjWH3zwwUa2Yx2oOkKQdI2kZZKerJg2WNLdkp4p/x3Us22aWW/oyiHDD4DD\n2k07H7gnInYF7il/N7M+rmogRMT9wMvtJh8FXFfevg44usF9mVkTdPek4tCIWFzeXgIMbVA/ZtZE\ndZ9UjIjIfYmrpIlA/n/dmFlL6O4IYamkYQDlv51+3G5ETIuIsRExtpvbMrNe0t1AmAlMKG9PAG5r\nTDtm1kxVDxkk3QyMA7aWtBC4ALgUmC7pVGABkP9AfQPgE5/4RLZe7/ciNNsGG+RfXz70oQ/Vtf57\n7723ruWtuqqBEBHHd1I6qMG9mFmT+dJlM0scCGaWOBDMLHEgmFniQDCzxIFgZok/D8Ea5qabbsrW\nx48fX9f6zz333Gx9hx12yNanT5+erd93333Z+tq1a7P1dYFHCGaWOBDMLHEgmFniQDCzxIFgZokD\nwcwSB4KZJb4OYR2y8847Z+tr1qzJ1seNG5etT5gwIVs/+uj8Z+1GdPpJe12y+eabZ+unnHJKXfWz\nzjorW586dWq2vi7wCMHMEgeCmSUOBDNLHAhmljgQzCxxIJhZ4kAws8TXIfSiq666Kls/9thjs/VR\no0Zl63fccUe2vnr16mx9+PDh2XpPmzNnTrY+c+bMbP1nP/tZtn7LLbdk69U+T2F94BGCmSUOBDNL\nHAhmljgQzCxxIJhZ4kAws8SBYGaJr0PoRYsWLcrWTzjhhGz9Jz/5SbY+YsSIbH3gwIHZer1mz56d\nrV944YXZ+owZM+ra/mabbZatL126tK71rw+qjhAkXSNpmaQnK6ZNkbRI0mPlz+E926aZ9YauHDL8\nADisg+nfjogx5U/+Ejkz6xOqBkJE3A+83Au9mFmT1XNScZKk2eUhxaCGdWRmTdPdQLgSeD8wBlgM\nfLOzGSVNlPSwpIe7uS0z6yXdCoSIWBoRb0XE28D3gX0z806LiLERMba7TZpZ7+hWIEgaVvHrMcCT\nnc1rZn1H1esQJN0MjAO2lrQQuAAYJ2kMEMB84LQe7HG98dhjj2Xru+yyS7Z+6KGHZutf+tKXsvWD\nDz44W581a1a2fswxx2TrPe3II4/M1vfaa69sfX343oVqqgZCRBzfweSre6AXM2syX7psZokDwcwS\nB4KZJQ4EM0scCGaWOBDMLFFE9N7GpN7b2Hpo7Nj8xaB33nlntv7KK69k6+PHj8/W582bl63Xa8iQ\nIdn6008/na0PGDAgWx82bFi2vnz58my91UWEqs3jEYKZJQ4EM0scCGaWOBDMLHEgmFniQDCzxIFg\nZom/l2Edss0222Tr1b6XoX///tn6G2+8UXNPjfTmm29m69W+d2HBggXZ+urVq2vuaV3jEYKZJQ4E\nM0scCGaWOBDMLHEgmFniQDCzxIFgZomvQ1iHjBkzpq7lH3/88Wx9xYoVda2/XmeeeWa2PmrUqGz9\n5JNPztZff/31mnta13iEYGaJA8HMEgeCmSUOBDNLHAhmljgQzCxxIJhZ4usQLFm0aFG2/tprr/Xo\n9s8999xs/aKLLsrW58yZk63PmDGj5p7WN1VHCJJ2lPQrSU9JmiPp7HL6YEl3S3qm/HdQz7drZj2p\nK4cMa4EvR8RoYD/gLEmjgfOBeyJiV+Ce8ncz68OqBkJELI6IR8vbrwJzge2Bo4DrytmuA47uqSbN\nrHfUdFJR0khgb+A3wNCIWFyWlgBDG9qZmfW6Lp9UlNQPuAX4QkS8Ir3zvZEREZ19kaukicDEehs1\ns57XpRGCpI0pwuDGiLi1nLxU0rCyPgxY1tGyETEtIsZGRP6ric2s6bryLoOAq4G5EfGtitJMYEJ5\newJwW+PbM7Pe1JVDhr8BTgKekPRYOW0ycCkwXdKpwALguJ5p0fqKTTfdNFs/++yzs/Vq1xlUHqZ2\n5LLLLsvWe/o6inVB1UCIiAeBzh6Jgxrbjpk1ky9dNrPEgWBmiQPBzBIHgpklDgQzSxwIZpb48xAs\n2WqrrbL1k046KVuv9nkGo0ePrrmnSt/5zney9euvv76u9ZtHCGZWwYFgZokDwcwSB4KZJQ4EM0sc\nCGaWOBDMLPF1COuQ559/vq7lDzzwwLrq1T6vYPny5dn6pEmTsnV/r0LP8wjBzBIHgpklDgQzSxwI\nZpY4EMwscSCYWeJAMLPE1yGsQ6ZPn56tjxgxIlu/+OKL69r+rFmzsvXTTz89W1+yZEld27f6eYRg\nZokDwcwSB4KZJQ4EM0scCGaWOBDMLHEgmFmiiOi9jUm9tzEze5eIyH9gBV0YIUjaUdKvJD0laY6k\ns8vpUyQtkvRY+XN4I5o2s+apOkKQNAwYFhGPSuoPPAIcDRwHvBYRl3V5Yx4hmDVNV0YIVS9djojF\nwOLy9quS5gLb19+embWamk4qShoJ7A38ppw0SdJsSddIGtTJMhMlPSzp4bo6NbMe1+WTipL6Ab8G\nLo6IWyUNBV4CAriI4rDilCrr8CGDWZN05ZChS4EgaWPgduAXEfGtDuojgdsj4q+qrMeBYNYkjXqX\nQcDVwNzKMChPNrY5BniyO02aWevoyrsM+wMPAE8Ab5eTJwPHA2MoDhnmA6eVJyBz6/IIwaxJGnbI\n0CgOBLPmacghg5mtPxwIZpY4EMwscSCYWeJAMLPEgWBmiQPBzBIHgpklDgQzSxwIZpY4EMwscSCY\nWeJAMLPEgWBmSdUPWW2wl4AFFb9vXU5rVe6vPq3cXyv3Bo3vb0RXZurVz0N4z8alhyNibNMaqML9\n1aeV+2vl3qB5/fmQwcwSB4KZJc0OhGlN3n417q8+rdxfK/cGTeqvqecQzKy1NHuEYGYtxIFgZokD\nwcwSB4KZJQ4EM0v+H24DVDRzv/gUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1ed03eca90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAAEMCAYAAAAiW8hnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1ecff32cd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAAEMCAYAAAAiW8hnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1ecc610ed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAAEMCAYAAAAiW8hnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVjgQzKz4f4atOzaF64R2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1ecc5aa890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nsample = 4\n",
    "rand_idx = np.random.randint(mnist.train.images.shape[0], size=nsample)\n",
    "\n",
    "for i in rand_idx:\n",
    "    curr_img = np.reshape(mnist.train.images[i, :], (28,28))\n",
    "    curr_lbl = np.argmax(mnist.train.labels[i, :])\n",
    "    plt.matshow(curr_img, cmap=plt.get_cmap('gray'))\n",
    "    plt.title(\"\"+str(i)+\"th training image \"\n",
    "              + \"(label: \" + str(curr_lbl) + \")\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001 #learning rate is used to reduce our cost/loss/cross entropy and helps in converging or reaching the local optima. The learning rate should neither be too high or too low it should be a balanced rate. \n",
    "training_iters = 200000 ##number of times we train our network, its like a loop which trains our network, calculates cost, optimizes it in every epoch, also in every epoch we take \n",
    "batch_size = 128 #this means that our training images will be divided in a fixed batch size and at every batch it will take a fixed number of images and train them. \n",
    "display_step = 10 #after how many epochs we want to output our desired results on screen\n",
    "\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 784 # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10 # MNIST total classes (0-9 digits)\n",
    "dropout = 0.75 # Dropout, probability to keep units, basically it helps in preventing overfitting our data\n",
    "\n",
    "# tf Graph input\n",
    "#placeholder is like a variable to which we will assign data later on. It will allow us to do operations and build our computation graph without feeding in data.\n",
    "#x will hold the training images in form of matrix,the dimensions of x will be in our case None*784, that is why we use None which allows us to vary the dimensionality of our rows.\n",
    "#we use float to define its type.\n",
    "x = tf.placeholder(\"float\", [None, n_input])\n",
    "#similarly y will hold the label of the training images in form matrix which will be a None*10 matrix. None will be replaced by the number of images we want to train on.\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "keep_prob = tf.placeholder(tf.float32) #dropout (keep probability), this drops some part of our network, so that it helps in backpropogation as computation increases and it also reduces vanishing gradient problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " #Input Image (28*28*1) -> Conv1(32 5*5*1) ->Conv1 (28*28*32)-> Maxpooling(2*2) -> Conv1 (14*14*32)\n",
    " \n",
    " #Conv1 (14*14*32) -> Conv2 (64 5*5*32) -> Conv2 (14*14*64) -> Maxpooling(2*2) -> Conv2 (7*7*64)\n",
    "    \n",
    " #Conv2 (7*7*64) -> Fully Connected (1024 7*7*64) -> Output Layer (1024 * 10) -> Predict Class    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create some wrappers for simplicity\n",
    "#Note the strides are set to 1 in all dimensions.The first and last stride must always be 1,because the first is for the image-number and the last is for the input-channel.the last is for the input-channel.\n",
    "#For e.g. strides=[1, 2, 2, 1] would mean that the filter is moved 2 pixels across the x- and y-axis of the image.\n",
    "#The padding is set to 'SAME' which means the input image is padded with zeroes so the size of the output is the same.\n",
    "def conv2d(x, W, b, strides=1):\n",
    "    # Conv2D wrapper, with bias and relu activation\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x) #apply relu to the image after doing the dot product with the filter and adding bias.\n",
    "\n",
    "#This is 2x2 max-pooling, which means that we consider 2x2 windows and select the largest value in each window. Then we move 2 pixels to the next window.\n",
    "def maxpool2d(x, k=2):\n",
    "    # MaxPool2D wrapper\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],padding='SAME')\n",
    "\n",
    "\n",
    "# Create model\n",
    "def conv_net(x, weights, biases, dropout):\n",
    "    # Reshape input picture\n",
    "    #x will recieve a tensor of dimension (None, 784), 784 dimension after flattening the image. \n",
    "    # 28,28 is the size of the image; the dimension will reduce. 1 is the number of channels in input image.\n",
    "    # -1 squashes/flattens the 28*28 input image in to a 1*784 column vector.\n",
    "    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "\n",
    "    # Convolution Layer\n",
    "    # here we call the conv2d function we had defined above and pass the input image x, weights wc1 and bias bc1.\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    # Max Pooling (down-sampling), this chooses the max value from a 2*2 matrix window and outputs a 14*14 matrix from a 28*28 matrix.\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "\n",
    "    # Convolution Layer\n",
    "    # here we call the conv2d function we had defined above and pass the input image x, weights wc2 and bias bc2.\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    # Max Pooling (down-sampling), this chooses the max value from a 2*2 matrix window and outputs a 7*7 matrix from a 14*14 matrix.\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "\n",
    "    # Fully connected layer\n",
    "    # Reshape conv2 output to fit fully connected layer input\n",
    "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    # Apply Dropout\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "\n",
    "    # Output, class prediction\n",
    "    # finally we multiply the fully connected layer with the weights and add a bias term, return the value and get a class prediction \n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store layers weight & bias\n",
    "#We pass 32 5*5*1 filter through our input image which is wc1, then we pass another 64 5*5*32 filter after which we pass a 1024 7*7*64 fully connected layer and finally a output layer with 1024*10 dimensions. We use 10 because we have 0-9 10 different classes in our model.\n",
    "#Our input image has 1 channel since its a gray scale image and so our first filter has 5*5*1 dimensions, if it would have been a RGB color image then the filter dimension would have been 5*5*3.\n",
    "weights = {\n",
    "    # 5x5 conv, 1 input, 32 outputs\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
    "    # 5x5 conv, 32 inputs, 64 outputs\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "    # fully connected, 7*7*64 inputs, 1024 outputs, since after max pooling on 28*28 we get 14*14 and then again pooling it to 7*7 we apply a fully connected layer with dimensions of 7*7*64.\n",
    "    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024])),\n",
    "    # 1024 inputs, 10 outputs (class prediction)\n",
    "    'out': tf.Variable(tf.random_normal([1024, n_classes]))\n",
    "}\n",
    "#similarly we have 2 bias for our filters, 1 for the fully connected layer and 1 for the output layer.\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([32])),\n",
    "    'bc2': tf.Variable(tf.random_normal([64])),\n",
    "    'bd1': tf.Variable(tf.random_normal([1024])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "# Construct model and we call the conv_net function by passing in x, weights and biases and keep_probability.\n",
    "pred = conv_net(x, weights, biases, keep_prob)\n",
    "\n",
    "# Define loss and optimizer. We use softmax loss function which is known as cross entropy loss function.\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "#for optimization we use Adam optimizer, we can use Gradient Descent as well.\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "\n",
    "# Evaluate model\n",
    "# Test model, here we check whether the index of the maximum value of the predicted image is equal to the actual labelled image and both will be a column vector.\n",
    "correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "#calculate accuracy across the correct_prediction using reduce_mean. For eg: if we have 10 classes and out of which only 4 classes predicted result was true so we will get something like 4/10 as accuracy.\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1280, Minibatch Loss= 31540.179688, Training Accuracy= 0.33594\n",
      "Iter 2560, Minibatch Loss= 10024.594727, Training Accuracy= 0.53906\n",
      "Iter 3840, Minibatch Loss= 7291.990234, Training Accuracy= 0.59375\n",
      "Iter 5120, Minibatch Loss= 5686.883789, Training Accuracy= 0.71875\n",
      "Iter 6400, Minibatch Loss= 6301.837891, Training Accuracy= 0.75000\n",
      "Iter 7680, Minibatch Loss= 2591.784668, Training Accuracy= 0.82812\n",
      "Iter 8960, Minibatch Loss= 3040.357910, Training Accuracy= 0.87500\n",
      "Iter 10240, Minibatch Loss= 2686.399170, Training Accuracy= 0.85156\n",
      "Iter 11520, Minibatch Loss= 2853.360840, Training Accuracy= 0.85156\n",
      "Iter 12800, Minibatch Loss= 2102.417236, Training Accuracy= 0.86719\n",
      "Iter 14080, Minibatch Loss= 2391.098633, Training Accuracy= 0.85938\n",
      "Iter 15360, Minibatch Loss= 1695.261963, Training Accuracy= 0.89844\n",
      "Iter 16640, Minibatch Loss= 1993.429565, Training Accuracy= 0.87500\n",
      "Iter 17920, Minibatch Loss= 1933.289307, Training Accuracy= 0.86719\n",
      "Iter 19200, Minibatch Loss= 2038.959229, Training Accuracy= 0.91406\n",
      "Iter 20480, Minibatch Loss= 2301.020264, Training Accuracy= 0.87500\n",
      "Iter 21760, Minibatch Loss= 1152.213135, Training Accuracy= 0.93750\n",
      "Iter 23040, Minibatch Loss= 1909.710815, Training Accuracy= 0.91406\n",
      "Iter 24320, Minibatch Loss= 3123.617920, Training Accuracy= 0.87500\n",
      "Iter 25600, Minibatch Loss= 1931.083496, Training Accuracy= 0.92188\n",
      "Iter 26880, Minibatch Loss= 1098.478271, Training Accuracy= 0.95312\n",
      "Iter 28160, Minibatch Loss= 1334.411011, Training Accuracy= 0.91406\n",
      "Iter 29440, Minibatch Loss= 1802.676880, Training Accuracy= 0.89844\n",
      "Iter 30720, Minibatch Loss= 656.918945, Training Accuracy= 0.92969\n",
      "Iter 32000, Minibatch Loss= 1127.556152, Training Accuracy= 0.92969\n",
      "Iter 33280, Minibatch Loss= 1085.382690, Training Accuracy= 0.91406\n",
      "Iter 34560, Minibatch Loss= 1083.996338, Training Accuracy= 0.92188\n",
      "Iter 35840, Minibatch Loss= 1406.930298, Training Accuracy= 0.93750\n",
      "Iter 37120, Minibatch Loss= 683.603760, Training Accuracy= 0.93750\n",
      "Iter 38400, Minibatch Loss= 1392.308960, Training Accuracy= 0.90625\n",
      "Iter 39680, Minibatch Loss= 1372.543091, Training Accuracy= 0.91406\n",
      "Iter 40960, Minibatch Loss= 535.370117, Training Accuracy= 0.94531\n",
      "Iter 42240, Minibatch Loss= 1408.181641, Training Accuracy= 0.91406\n",
      "Iter 43520, Minibatch Loss= 1092.865234, Training Accuracy= 0.95312\n",
      "Iter 44800, Minibatch Loss= 646.227417, Training Accuracy= 0.94531\n",
      "Iter 46080, Minibatch Loss= 1022.309998, Training Accuracy= 0.91406\n",
      "Iter 47360, Minibatch Loss= 736.623901, Training Accuracy= 0.94531\n",
      "Iter 48640, Minibatch Loss= 914.813232, Training Accuracy= 0.92969\n",
      "Iter 49920, Minibatch Loss= 836.482849, Training Accuracy= 0.93750\n",
      "Iter 51200, Minibatch Loss= 143.315353, Training Accuracy= 0.97656\n",
      "Iter 52480, Minibatch Loss= 359.074951, Training Accuracy= 0.94531\n",
      "Iter 53760, Minibatch Loss= 540.182495, Training Accuracy= 0.96094\n",
      "Iter 55040, Minibatch Loss= 184.435913, Training Accuracy= 0.98438\n",
      "Iter 56320, Minibatch Loss= 283.548706, Training Accuracy= 0.96875\n",
      "Iter 57600, Minibatch Loss= 784.775818, Training Accuracy= 0.92188\n",
      "Iter 58880, Minibatch Loss= 533.455139, Training Accuracy= 0.95312\n",
      "Iter 60160, Minibatch Loss= 1076.420898, Training Accuracy= 0.94531\n",
      "Iter 61440, Minibatch Loss= 419.556030, Training Accuracy= 0.94531\n",
      "Iter 62720, Minibatch Loss= 500.569641, Training Accuracy= 0.95312\n",
      "Iter 64000, Minibatch Loss= 533.521301, Training Accuracy= 0.93750\n",
      "Iter 65280, Minibatch Loss= 309.480591, Training Accuracy= 0.96094\n",
      "Iter 66560, Minibatch Loss= 441.446838, Training Accuracy= 0.93750\n",
      "Iter 67840, Minibatch Loss= 565.569824, Training Accuracy= 0.95312\n",
      "Iter 69120, Minibatch Loss= 319.299896, Training Accuracy= 0.96875\n",
      "Iter 70400, Minibatch Loss= 572.854370, Training Accuracy= 0.96094\n",
      "Iter 71680, Minibatch Loss= 368.369446, Training Accuracy= 0.96094\n",
      "Iter 72960, Minibatch Loss= 580.041260, Training Accuracy= 0.96875\n",
      "Iter 74240, Minibatch Loss= 487.809052, Training Accuracy= 0.96094\n",
      "Iter 75520, Minibatch Loss= 451.643250, Training Accuracy= 0.96094\n",
      "Iter 76800, Minibatch Loss= 50.068649, Training Accuracy= 0.98438\n",
      "Iter 78080, Minibatch Loss= 401.764160, Training Accuracy= 0.94531\n",
      "Iter 79360, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 80640, Minibatch Loss= 643.459961, Training Accuracy= 0.95312\n",
      "Iter 81920, Minibatch Loss= 700.643433, Training Accuracy= 0.95312\n",
      "Iter 83200, Minibatch Loss= 585.430847, Training Accuracy= 0.96094\n",
      "Iter 84480, Minibatch Loss= 816.522217, Training Accuracy= 0.96875\n",
      "Iter 85760, Minibatch Loss= 357.611572, Training Accuracy= 0.96094\n",
      "Iter 87040, Minibatch Loss= 324.462280, Training Accuracy= 0.96875\n",
      "Iter 88320, Minibatch Loss= 181.259247, Training Accuracy= 0.96094\n",
      "Iter 89600, Minibatch Loss= 486.246704, Training Accuracy= 0.94531\n",
      "Iter 90880, Minibatch Loss= 595.817017, Training Accuracy= 0.92969\n",
      "Iter 92160, Minibatch Loss= 503.650818, Training Accuracy= 0.94531\n",
      "Iter 93440, Minibatch Loss= 486.948395, Training Accuracy= 0.96875\n",
      "Iter 94720, Minibatch Loss= 648.636047, Training Accuracy= 0.96875\n",
      "Iter 96000, Minibatch Loss= 257.890717, Training Accuracy= 0.96875\n",
      "Iter 97280, Minibatch Loss= 613.068359, Training Accuracy= 0.95312\n",
      "Iter 98560, Minibatch Loss= 500.759766, Training Accuracy= 0.96094\n",
      "Iter 99840, Minibatch Loss= 318.451141, Training Accuracy= 0.93750\n",
      "Iter 101120, Minibatch Loss= 533.584473, Training Accuracy= 0.96094\n",
      "Iter 102400, Minibatch Loss= 163.934921, Training Accuracy= 0.97656\n",
      "Iter 103680, Minibatch Loss= 133.708313, Training Accuracy= 0.97656\n",
      "Iter 104960, Minibatch Loss= 291.945129, Training Accuracy= 0.95312\n",
      "Iter 106240, Minibatch Loss= 392.741577, Training Accuracy= 0.92188\n",
      "Iter 107520, Minibatch Loss= 573.417114, Training Accuracy= 0.97656\n",
      "Iter 108800, Minibatch Loss= 302.843567, Training Accuracy= 0.96094\n",
      "Iter 110080, Minibatch Loss= 184.546951, Training Accuracy= 0.97656\n",
      "Iter 111360, Minibatch Loss= 158.656128, Training Accuracy= 0.98438\n",
      "Iter 112640, Minibatch Loss= 440.818359, Training Accuracy= 0.92969\n",
      "Iter 113920, Minibatch Loss= 108.167740, Training Accuracy= 0.98438\n",
      "Iter 115200, Minibatch Loss= 247.794922, Training Accuracy= 0.96094\n",
      "Iter 116480, Minibatch Loss= 274.271271, Training Accuracy= 0.96094\n",
      "Iter 117760, Minibatch Loss= 164.571487, Training Accuracy= 0.96875\n",
      "Iter 119040, Minibatch Loss= 99.337303, Training Accuracy= 0.99219\n",
      "Iter 120320, Minibatch Loss= 162.401581, Training Accuracy= 0.95312\n",
      "Iter 121600, Minibatch Loss= 137.631790, Training Accuracy= 0.96875\n",
      "Iter 122880, Minibatch Loss= 311.191223, Training Accuracy= 0.95312\n",
      "Iter 124160, Minibatch Loss= 133.738205, Training Accuracy= 0.96875\n",
      "Iter 125440, Minibatch Loss= 364.166687, Training Accuracy= 0.95312\n",
      "Iter 126720, Minibatch Loss= 292.839966, Training Accuracy= 0.96094\n",
      "Iter 128000, Minibatch Loss= 132.429840, Training Accuracy= 0.96094\n",
      "Iter 129280, Minibatch Loss= 310.926392, Training Accuracy= 0.95312\n",
      "Iter 130560, Minibatch Loss= 307.123993, Training Accuracy= 0.97656\n",
      "Iter 131840, Minibatch Loss= 45.111160, Training Accuracy= 0.98438\n",
      "Iter 133120, Minibatch Loss= 227.258179, Training Accuracy= 0.97656\n",
      "Iter 134400, Minibatch Loss= 42.990753, Training Accuracy= 0.98438\n",
      "Iter 135680, Minibatch Loss= 281.738708, Training Accuracy= 0.96875\n",
      "Iter 136960, Minibatch Loss= 77.213531, Training Accuracy= 0.97656\n",
      "Iter 138240, Minibatch Loss= 247.707855, Training Accuracy= 0.97656\n",
      "Iter 139520, Minibatch Loss= 447.767548, Training Accuracy= 0.94531\n",
      "Iter 140800, Minibatch Loss= 79.416969, Training Accuracy= 0.96875\n",
      "Iter 142080, Minibatch Loss= 180.866104, Training Accuracy= 0.95312\n",
      "Iter 143360, Minibatch Loss= 188.863800, Training Accuracy= 0.98438\n",
      "Iter 144640, Minibatch Loss= 94.145889, Training Accuracy= 0.97656\n",
      "Iter 145920, Minibatch Loss= 119.133713, Training Accuracy= 0.98438\n",
      "Iter 147200, Minibatch Loss= 332.276947, Training Accuracy= 0.96094\n",
      "Iter 148480, Minibatch Loss= 124.882492, Training Accuracy= 0.96875\n",
      "Iter 149760, Minibatch Loss= 228.463150, Training Accuracy= 0.98438\n",
      "Iter 151040, Minibatch Loss= 547.978882, Training Accuracy= 0.93750\n",
      "Iter 152320, Minibatch Loss= 248.812286, Training Accuracy= 0.96094\n",
      "Iter 153600, Minibatch Loss= 129.168655, Training Accuracy= 0.96094\n",
      "Iter 154880, Minibatch Loss= 315.828125, Training Accuracy= 0.96875\n",
      "Iter 156160, Minibatch Loss= 257.262695, Training Accuracy= 0.97656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 157440, Minibatch Loss= 123.597115, Training Accuracy= 0.97656\n",
      "Iter 158720, Minibatch Loss= 51.359531, Training Accuracy= 0.97656\n",
      "Iter 160000, Minibatch Loss= 42.420990, Training Accuracy= 0.99219\n",
      "Iter 161280, Minibatch Loss= 140.845337, Training Accuracy= 0.98438\n",
      "Iter 162560, Minibatch Loss= 307.216980, Training Accuracy= 0.96875\n",
      "Iter 163840, Minibatch Loss= 67.892838, Training Accuracy= 0.98438\n",
      "Iter 165120, Minibatch Loss= 28.960442, Training Accuracy= 0.99219\n",
      "Iter 166400, Minibatch Loss= 130.503799, Training Accuracy= 0.96094\n",
      "Iter 167680, Minibatch Loss= 6.974297, Training Accuracy= 0.99219\n",
      "Iter 168960, Minibatch Loss= 123.338348, Training Accuracy= 0.96875\n",
      "Iter 170240, Minibatch Loss= 116.928535, Training Accuracy= 0.98438\n",
      "Iter 171520, Minibatch Loss= 517.482605, Training Accuracy= 0.96094\n",
      "Iter 172800, Minibatch Loss= 332.341858, Training Accuracy= 0.99219\n",
      "Iter 174080, Minibatch Loss= 203.065445, Training Accuracy= 0.95312\n",
      "Iter 175360, Minibatch Loss= 162.362946, Training Accuracy= 0.97656\n",
      "Iter 176640, Minibatch Loss= 361.192261, Training Accuracy= 0.96875\n",
      "Iter 177920, Minibatch Loss= 96.489235, Training Accuracy= 0.96875\n",
      "Iter 179200, Minibatch Loss= 142.502197, Training Accuracy= 0.97656\n",
      "Iter 180480, Minibatch Loss= 7.850983, Training Accuracy= 0.99219\n",
      "Iter 181760, Minibatch Loss= 157.779831, Training Accuracy= 0.98438\n",
      "Iter 183040, Minibatch Loss= 431.841034, Training Accuracy= 0.94531\n",
      "Iter 184320, Minibatch Loss= 70.724617, Training Accuracy= 0.99219\n",
      "Iter 185600, Minibatch Loss= 27.284670, Training Accuracy= 0.98438\n",
      "Iter 186880, Minibatch Loss= 33.038658, Training Accuracy= 0.99219\n",
      "Iter 188160, Minibatch Loss= 225.488297, Training Accuracy= 0.96875\n",
      "Iter 189440, Minibatch Loss= 266.069397, Training Accuracy= 0.95312\n",
      "Iter 190720, Minibatch Loss= 6.994904, Training Accuracy= 0.99219\n",
      "Iter 192000, Minibatch Loss= 163.728180, Training Accuracy= 0.97656\n",
      "Iter 193280, Minibatch Loss= 197.818680, Training Accuracy= 0.96875\n",
      "Iter 194560, Minibatch Loss= 205.734833, Training Accuracy= 0.96875\n",
      "Iter 195840, Minibatch Loss= 168.608612, Training Accuracy= 0.97656\n",
      "Iter 197120, Minibatch Loss= 35.664322, Training Accuracy= 0.97656\n",
      "Iter 198400, Minibatch Loss= 168.571609, Training Accuracy= 0.96094\n",
      "Iter 199680, Minibatch Loss= 32.822113, Training Accuracy= 0.99219\n",
      "Optimization Finished!\n",
      "('Testing Accuracy:', 0.97600001)\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph. #this is a class that runs all the tensorflow operations and launches the graph in a session. All the operations have to be within the indentation. \n",
    "with tf.Session() as sess:\n",
    "    sess.run(init) #sess.run(init), runs the variables that were initialised in the previous step and evaluates the tensor \n",
    "\n",
    "#instead of using for loop we use while loop and intialize step = 1 and at every time step we increment step = step + 1.\n",
    "#since our batch size is 128 and display step is 10 so we display our output for only those Iterations where the Step after dividing by the display_Step leaves a remainder zero.\n",
    "#we then input the images in batch_x and their respective labels in batch_y and run an optimizer by feeding in x, y, and dropout. Here are placeholders x,y,and keep_prob gets their value.\n",
    "#after that we display the Iteration number, the Minibatch loss and the training accuracy by calling the cost and the accuracy function.\n",
    "    step = 1\n",
    "    # Keep training until reach max iterations\n",
    "    while step * batch_size < training_iters:\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        # Run optimization op (backprop), we use keep_prob to drop some part of the network and as dropout is 0.75, so it will keep 75% of the network and drop the 25%, which helps in reducing the computational complexity and vanishing gradient problem while backpropogating through the network.\n",
    "        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y,\n",
    "                                       keep_prob: dropout})\n",
    "        if step % display_step == 0:\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss, acc = sess.run([cost, accuracy], feed_dict={x: batch_x,\n",
    "                                                              y: batch_y,\n",
    "                                                              keep_prob: 1.})\n",
    "            print(\"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.5f}\".format(acc))\n",
    "        step += 1\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Calculate accuracy for 250 mnist test images\n",
    "    print(\"Testing Accuracy:\", sess.run(accuracy, feed_dict={x: mnist.test.images[:250],y : mnist.test.labels[:250],keep_prob: 1.}))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
